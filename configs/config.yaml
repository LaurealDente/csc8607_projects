dataset:
  name: imagenet                # ex: "CIFAR10", "IMDB", ...
  root: "zh-plus/tiny-imagenet"            # chemin local pour les données
  split:                    # optionnel : noms/tailles de splits
    train:
      p: 0.9
      chemin: data/preprocessed_dataset_train.pt
    val: 
      p: 0
      chemin: data/preprocessed_dataset_valid.pt
    test: 
      p: 0.1
      chemin: data/preprocessed_dataset_test.pt
  download: true            # si supporté
  num_workers: 8
  shuffle: true
  columns:
    label: label
    image : image

preprocess:
  # transformations de base (ex: resize, normalize)
  resize: null                   # ex: [32, 32] ou null
  normalize: True
  text_tokenizer: null         # pour NLP : nom ou paramètres, sinon null

augment:
  # data augmentation (laisser null si non utilisée)
  random_flip: true
  random_crop:  
    size: [64, 64]
    scale: [0.8,1.0]
    ratio: [1.0,1.0]
  color_jitter:
    brightness: 0.1
    contrast: 0.1
    saturation: 0.1
    hue: 0.1

model:
  type: Convolutional Neural Network - Residual Network                # ex: "resnet18", "mlp", "lstm", ...
  num_classes: 200
  in_channels: 3
  input_shape: [32,3,64,64]             # ex: [3, 32, 32] ou null
  hidden_sizes: [64,64,128,256,200]
  activation: relu       # ex: 0.0–0.5
  stage_widths: [64, 128, 256]
  batch_norm: True         # true/false
  residual: True           # true/false
  final_test : 
    A :
      dropout : 0.1
      blocks_config : [3,3,3] 
    B :
      dropout : 0.1
      block_config : [2,2,2]


train:
  seed: 42
  device: cuda              # "cpu", "cuda", ou "auto"
  batch_size: 32
  epochs: 100
  max_steps: null           # entier ou null
  overfit_small: false      # true pour sur-apprendre sur un petit échantillon
  overfit_epochs : 100
  finder_start_lr: 1.0e-8 
  taille_finder: 10000

  optimizer:
    name: adam              # sgd/adam/rmsprop
    lr: 0.001
    weight_decay: 0.0
    over_weight_decay: 0.0
    momentum: 0.9           # utile si SGD

  scheduler:
    name: none              # none/step/cosine/onecycle
    step_size: 10
    gamma: 0.1
    warmup_steps: 0

metrics:
  classification:           # ex: ["accuracy", "f1"]
    - accuracy
  regression: []            # ex: ["mae", "rmse"]

hparams:                    # espace pour mini grid search
  lr: [0.0005, 0.001, 0.005]
  num_blocks: [2,3] 
  batch_size: [32, 64]
  weight_decay: [0.0, 0.0005]

grid_search:
  hparams:
    lr: [0.0001]
    weight_decay: [0.0001]
    dropout: [0.1, 0.3]
    block_config: [[2, 2, 2], [3, 3, 3]]
  subset_size:
    train : 10000 
    val : 3000
  epochs : 15

  model:
    B1: 2
    B2: 2
    B3: 2 
    residual: True
    batch_norm: True
    fonction: relu
    num_classes: 200

paths:
  runs_dir: "./runs"
  artifacts_dir: "./artifacts"